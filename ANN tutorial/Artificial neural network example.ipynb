{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f47ffa88",
   "metadata": {},
   "source": [
    "# Artificial Neural Netowork"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95894253",
   "metadata": {},
   "source": [
    "In this tutorial, I will showcase how to use aritifical neural network (ANN) in Tensorflow.\n",
    "\n",
    "Tensorflow is a deep learning package implemented on python. Very broadly speaking, tensorflow allows us to use GPU without much effort. It is a package that is an overlay ontop of popular math-packages, like numpy, scipy and sklearn, and converts arrays into something GPU can handle. You can also use pytorch, if you prefer, but the paper we are reproducing utilizes tensorflow. Please check tensorflow website for more details [TensorFlow Website](https://www.tensorflow.org/)\n",
    "\n",
    "Please begin by running the below code to install the relevant packages. If there is some kind of error, remove the -q to display error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeb734a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\yutah\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\yutah\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yutah\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\yutah\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\yutah\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\yutah\\anaconda3\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yutah\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\yutah\\anaconda3\\lib\\site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\yutah\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\yutah\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yutah\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow\n",
    "!pip install -q numpy \n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eabd37",
   "metadata": {},
   "source": [
    "![title](img/ANN_network.png)\n",
    "ANN contains 3 main parts.\n",
    "1) The input layer: Vectorized data. For single cell we will preprocess the data to about ~1000 features. See the [Scanpy tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html) on clustering to see how this is performed\n",
    "2) Hidden layer: This is the 'black box' portion of deep learning. We need to determine how many hidden layers we want, and the number of nodes (the circles) we want\n",
    "3) Output layers: This is where we compare our prediction with the true solution. For classification, if there are 10 classes, we would have 10 nodes. For regression, this will depend on the architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61788b3",
   "metadata": {},
   "source": [
    "# Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beeea9f",
   "metadata": {},
   "source": [
    "Let us begin by talking breifly about the notation.\n",
    "1) Our data will be $X \\in \\mathbb{R}^{M,N}$. This means we have $M$ data, and $N$ features, where the rows of matrix $X$ correspond to each data, and the columns indicate the features. Let $Y \\in \\mathbb{R}^N$ be the labels, or the true cell type. For classification problem, the labels will be some integer, and for regression problem, the label will be some number. \n",
    "\n",
    "An example of our data may look like the following:\n",
    "\n",
    "data | gene 1 | gene 2| ... | gene N|Label|\n",
    "| :-: | :-: | :-: |:-: | :-:|:-:|\n",
    "cell 1 | 0 | 10 | ... | 0 | Oligodendrocytes |\n",
    "cell 2 | 0.1 | 0 | ... | 100|Oligodendrocytes |\n",
    "... | ... | ... | ... | ...|...|\n",
    "cell M | 100 | 0| ... | 100|Astrocytes |\n",
    "\n",
    "2) The $i$-th data will be often be denoted as $\\mathbf{x}_i$, which is a vector of length $N$ (features). Then, $\\mathbf{x}_i = (x_{i1}, ..., x_{ij}, ...,x_{iN})$, where $x_{ij}$ is the $j$-th feature of data $i$.\n",
    "\n",
    "3) Similarly, the $i$-th label is denoted as $y_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade7ba75",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "Let us start by first obtaining the digits dataset from tensorflow.\n",
    "\n",
    "First, import relevant librarie.\n",
    "Run the following code to load the digits dataset. \n",
    "\n",
    "MNIST is a 28 by 28 digit image, where the goal is to classify the digits from 1 to 10.\n",
    "\n",
    "We will do a scaling on the data so that each pixel has a value between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cd0aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt #this is for plotting our digits\n",
    "import numpy as np\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b1b733d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2, 5)\n",
    "row, col = 0, 0\n",
    "for idx in range(10):\n",
    "    ax[row, col].imshow(x_train[idx])\n",
    "    ax[row, col].axis('off')\n",
    "    col += 1\n",
    "    if col == 5:\n",
    "        row = 1; col =0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af66d22e",
   "metadata": {},
   "source": [
    "MNIST has 60,000 image as a training set, and 10,000 images as a testing set. That is, we train our machine learning model with the 60,000 images, and validate our model using the testing set.\n",
    "\n",
    "For the sake of learning the material, this is very big, and is not practicle. I will reduce the training set to 1000 and the testing set to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ef0ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_subset(x_train, y_train, subsample = 1000):\n",
    "    numClass = int(subsample / 10)\n",
    "    new_x_train = np.zeros([numClass * 10, x_train.shape[1], x_train.shape[2]])\n",
    "    new_y_train = np.zeros([numClass * 10])\n",
    "    for label in range(10):\n",
    "        index = np.where(y_train == label)[0]\n",
    "        new_x_train[label*numClass:(label+1)*numClass, :, :] = x_train[index[:numClass], :, :]\n",
    "        new_y_train[label*numClass:(label+1)*numClass] = y_train[index[:numClass]]\n",
    "    return new_x_train, new_y_train\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a1bf366",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data\n",
      "training (1000, 28, 28)\n",
      "testing (100, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#skip this line if you want to do the full data\n",
    "x_train, y_train = mnist_subset(x_train, y_train, subsample = 1000)\n",
    "x_test, y_test = mnist_subset(x_test, y_test, subsample = 100)\n",
    "print('Size of data')\n",
    "print('training', x_train.shape)\n",
    "print('testing', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13dee1",
   "metadata": {},
   "source": [
    "# ANN architecture: Feed Forward\n",
    "![title](img/neuron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a442101",
   "metadata": {},
   "source": [
    "1) Each neuron (the circle in the figure above) requires an input, weight, bias and activation\n",
    "2) Input is either the raw data or the hidden layer.\n",
    "3) Each neuron is computed as the following \n",
    "\\begin{align*}\n",
    "    h = \\sum_{i=1}^m w_ix_i + b\n",
    "\\end{align*}\n",
    "where $b$ is the bias, and $w_i$ is the weights.\n",
    "\n",
    "If we only have 1 neuron, this is essentially a line of best fit equation,\n",
    "\\begin{align*}\n",
    "    y = a_1x_1 + a_2x_2 + ... + a_mx_m + b\n",
    "\\end{align*}\n",
    "\n",
    "4) The activation function is a nonlinear function that converts $h$ to some positive number. We utilize activation to introduce nonlinearity to deep learning models. Otherwise, deep learning will just be a bunch of linear regression put together.\n",
    "\n",
    "5) Comon activation functions are ReLu, sigmoid, softmax. See tensorflow's page for all the different types. [Tensor Flow activation](https://www.tensorflow.org/api_docs/python/tf/keras/activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c465b03c",
   "metadata": {},
   "source": [
    "![title](img/ANN_network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd35581",
   "metadata": {},
   "source": [
    "Now, if we consider a group of neurons, we have to use matrix notation.\n",
    "\n",
    "1) The input layer, we denote $x$. This is essentially your raw data. Then, the first hidden layer $H_1$ is defined as \n",
    "\\begin{align*}\n",
    "H_1 = xW_1 + b_1\n",
    "\\end{align*}\n",
    "In this example, $x \\in \\mathbb{R}^{4}$, $W_1 \\in \\mathbb{R}^{4 \\times 5}$, and $b_1 \\in \\mathbb{R}^{5}$, and $H_1 \\in \\mathbb{R}^{4 \\times 5}$, where $M$ is the number of data.\n",
    "2) Then, we use the activation function $f_1$\n",
    "\\begin{align*}\n",
    "    f_1 = ReLu(H_1)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7c3838",
   "metadata": {},
   "source": [
    "3) The second hidden layer $H_2$ will be computed using the input $f_1$ from the previous layer.\n",
    "\\begin{align*}\n",
    "H_2 = f_1W_2 + b_2\n",
    "\\end{align*}\n",
    "4) One again, we use an activation function\n",
    "\\begin{align*}\n",
    "    f_2 = ReLu(H_2)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3e3f28",
   "metadata": {},
   "source": [
    "5) Now, we compute the output layer, which is essentially the exact same thing\n",
    "\\begin{align*}\n",
    "    H_3 = f_2W_3 + b_3\n",
    "\\end{align*}\n",
    "\n",
    "The only difference here is that the number of output layer is predetermined. If we have 10 class (as in the MNIST data), we will have 10 nodes.\n",
    "\n",
    "6) Often times for classification, we use softmax function for the output layers\n",
    "\\begin{align*}\n",
    "    \\hat{y} = softmax(H_3)\n",
    "\\end{align*}\n",
    "where $softmax = \\frac{e^{H_{3}^i}}{\\sum e^{H_{3}^i}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26a06d9",
   "metadata": {},
   "source": [
    "# ANN: Back Propagation\n",
    "![title](img/backprop.png)\n",
    "Now, the only thing left to do is determine what the weights, $W_1, W_2, W_3$ and the biases $b_1, b_2, b_3$ are. These quantities are obtained via lots of derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5985b269",
   "metadata": {},
   "source": [
    "Before we begin the back propagation, we need to define a loss function. I would refer to this video on [cross entropy](https://youtu.be/YtebGVx-Fxw?si=x3c88U4bkJ1A4zfe) to learn about why we use cross-entropy function\n",
    "\n",
    "The loss function is given as\n",
    "\\begin{align*}\n",
    "    L = - \\sum_i y_i \\log(\\hat{y})_i)\n",
    "\\end{align*}\n",
    "where $y_i$ is the true label, and $\\hat{y}_i$ is the predicted label from setp (6).\n",
    "\n",
    "Compute the partial derivative with respect to $W_1, W_2, W_3, b_1, b_2, b_3$ to obtain the weights and biases\n",
    "\n",
    "It is very much worth your time to calculate these derivatives, if you are interested in pursuing some kind of career in deep learning. Otherwise, for the sake of the project, we will just assume these derivatives are ok."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035427a7",
   "metadata": {},
   "source": [
    "# Tensorflow implementation\n",
    "\n",
    "We will use the 'Sequential' model to construct our ANN. I will also use Relu for the activation function.\n",
    "\n",
    "Sequential is useful for stacking layers where each layer has one input tensor and one output tensor. Layers are functions with a known mathematical structure that can be reused and have trainable variables. Most TensorFlow models are composed of layers. This model uses the Flatten, Dense, and Dropout layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9553d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),  #This is just to convert the image to a vector of length 28*28\n",
    "  tf.keras.layers.Dense(256, activation='relu'),   #256 is the number of noden in hiden layer 1\n",
    "  tf.keras.layers.Dense(128, activation='relu'),   # number of nodes in hiden layer 2 \n",
    "  tf.keras.layers.Dense(10)    #output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba398dd",
   "metadata": {},
   "source": [
    "Now, we need an output from our last layer, which has 10 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14e0bbae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6608275 , -0.2821433 ,  0.02270977, -0.27555802, -0.22411369,\n",
       "        -0.18071389, -0.59717596,  0.20937912,  0.06395733,  0.28594387]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8a68c5",
   "metadata": {},
   "source": [
    "Notice that these values have negatives, and it is difficult to understand what the heck these values mean. Therefore, we apply the softmax activation function to convert these values into probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3bf16ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05824145, 0.08505359, 0.11536887, 0.08561555, 0.09013523,\n",
       "        0.09413321, 0.06206914, 0.13904588, 0.12022707, 0.15011005]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c403d987",
   "metadata": {},
   "source": [
    "This means that the probability of digit being '0' is the first entry, the probability of digit '1' is the second entry, and so on\n",
    "\n",
    "Now, we define the loss function (the cross entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04419169",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a187892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb762b67",
   "metadata": {},
   "source": [
    "Now, we are basically done. The last step is to train our model using our 1,000 training data. We are using the 'adam' optimizer. This is a optimization scheme that utilizes stochastic gradient descent, which is essentially a computing the partial derivatives, but only using a subset of the data to speed up computation. See this [video](https://www.youtube.com/watch?v=vMh0zPT0tLI) for a quick tutorial\n",
    "\n",
    "In machine learning 'epoch' means number of iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5aba7ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 1s 2ms/step - loss: 1.3438 - accuracy: 0.6130\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.8790\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2858 - accuracy: 0.9310\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9610\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1165 - accuracy: 0.9730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a6f9cada90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b798f32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.3266 - accuracy: 0.8800 - 93ms/epoch - 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32657182216644287, 0.8799999952316284]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a58df",
   "metadata": {},
   "source": [
    "Our evaluation show that with our testing set, we get ~90% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f29353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edb05de4",
   "metadata": {},
   "source": [
    "# Extension to ANN\n",
    "\n",
    "We have now done the most basic ANN.\n",
    "\n",
    "It is really up to the researchers to fine tune parameters to get the best results.\n",
    "\n",
    "for example, we can change the number of nodes in the hidden layers and change the activation function. \n",
    "\n",
    "Lastly, I want to introduce the concept called 'Drop out'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cccb96c",
   "metadata": {},
   "source": [
    "![title](img/ANN_dropout.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d616b5",
   "metadata": {},
   "source": [
    "In deep learning, we have a concept call 'over fitting', where our model now fits to the noise, rather than the useful data. We introduce a concept called 'drop out' to reduce the effect of overfitting. There are 2 types of dropout\n",
    "1) Eliminate a node in the hidden layer\n",
    "2) Eliminate some of the connections.\n",
    "\n",
    "Both are valid strategies, and luckily, tensorflow has a nice implementation. I set the drop out to be 20%, ie we eliminate 20% of the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbe9b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49a736f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.4873 - accuracy: 0.5590\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.7960\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8840\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.9020\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.9280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a6fc767190>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dropout.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "model_dropout.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7310bf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.3495 - accuracy: 0.8700 - 79ms/epoch - 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3494838774204254, 0.8700000047683716]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dropout.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0be854",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d17afb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
