{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3783d203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\yutah\\appdata\\local\\anaconda3\\lib\\site-packages (3.2)\n",
      "Requirement already satisfied: anndata in c:\\users\\yutah\\appdata\\local\\anaconda3\\lib\\site-packages (0.10.5.post1)\n",
      "Requirement already satisfied: array-api-compat in c:\\users\\yutah\\appdata\\local\\anaconda3\\lib\\site-packages (from anndata) (1.4.1)\n",
      "Requirement already satisfied: h5py>=3 in c:\\users\\yutah\\appdata\\local\\anaconda3\\lib\\site-packages (from anndata) (3.9.0)\n",
      "Requirement already satisfied: natsort in c:\\users\\yutah\\appdata\\local\\anaconda3\\lib\\site-packages (from anndata) (8.4.0)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\yutah\\appdata\\local\\anaconda3\\lib\\site-packages (from anndata) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20 in c:\\users\\yutah\\appdata\\local\\anaconda3\\lib\\site-packages (from anndata) (23.1)\n",
      "Requirement already satisfied: pandas!=2.1.0rc0,!=2.1.2,>=1.1.1 in c:\\users\\yutah\\appdata\\local\\anaconda3\\lib\\site-packages (from anndata) (2.0.3)\n",
      "Requirement already satisfied: scipy>1.4 in c:\\users\\yutah\\appdata\\local\\anaconda3\\lib\\site-packages (from anndata) (1.11.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yutah\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas!=2.1.0rc0,!=2.1.2,>=1.1.1->anndata) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yutah\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas!=2.1.0rc0,!=2.1.2,>=1.1.1->anndata) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\yutah\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas!=2.1.0rc0,!=2.1.2,>=1.1.1->anndata) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yutah\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0rc0,!=2.1.2,>=1.1.1->anndata) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wget\n",
    "!pip install anndata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e196980",
   "metadata": {},
   "source": [
    "# Donwloading the data\n",
    "1) Begin by running the download_data.py in the SingleCellProcess folder (please run the above code if you do not have wget installed.\n",
    "2) There are 6 datasets that will be downloaded\n",
    "3) GSE75748 cell consists of different cells originating from H1 stem cells\n",
    "4) GSE75748 time consists of H1 cells sequenced in a hypoxic environment at different time. The goal is to see changes in gene expression.\n",
    "5) The last dataset consists of 4 sub-dataset. GSE84133 human 1,2,3,4. I would like you all to merge the dataset together to generate a large dataset of about 9000 cells.\n",
    "6) Once the dataset is downloaded, the data can be found as a csv file (open with excel) under ./SingleCellDataProcess/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44921e6",
   "metadata": {},
   "source": [
    "# Task for this week\n",
    "1) Using the above datasets, construct a machine learning classification model to achieve the best results.\n",
    "2) Begin by preprocessing the data using the scanpy tutorial (see code below to generate the AnnData type). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d17fbb6",
   "metadata": {},
   "source": [
    "# Some tips\n",
    "1) Run a basic statistics on the gene expression, as shown in scanpy, and decide how much data to keep.\n",
    "2) Look at the class size of each cell types. Unbalanced data is extremely hard to train. For example, if I divide the data into a training and testing data with 100 bunnies and 10 turtles, both training and testing data will have alot more bunnies. Training your model with such data can show bias towards bunnies. You may need to balance the data. \n",
    "3) When you traing any models, fix a random_state. All machine learning models utilize stochastic gradient descent, which computes derivatives using only parts of your data. How these data are chosen is based on random number generator. By fixing the random_state, you will always have the same result. To make sure your method is working properly, test your method with multiple (about 5) random state. For actual papers, many people do 30-100 random_state. Check [this video](https://youtu.be/vMh0zPT0tLI?si=r7mbTQSdTnU4qmCe) for more info on stocahstic gradient descent.\n",
    "3) For any questions (small or big) please let me know"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7e08d2",
   "metadata": {},
   "source": [
    "# Models to test\n",
    "There are hundreds of classification models, each with their own upside and downside.\n",
    "The model you select will depend on the number of data you have, the number of features, underlying assumptions, and more. Just because you have a lot of features, it does not mean you have a lot of 'good' features. ScRNA-seq is a fantastic example of bad large number of features. Additionally, if your features are in fact linearly dependent, then your features may also be bad.\n",
    "\n",
    "## You can check out the following to test your model (I am only listing ones that you can implement easily using the scikit-learn package from python)\n",
    "1) [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)\n",
    "2) [Linear Support Vector](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC)\n",
    "3) [Kernel Support Vector](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
    "- look at the 'kernel' and 'degree' parameters. These values can be used to optimize your model\n",
    "4) [Nearest Neighbors](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
    "5) [Decission Tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    "6) [Random Forest Decission Tree](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n",
    "7) [Gradient Boosting Decision Tree](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier)\n",
    "8) [Artificial Neural Network](https://www.tensorflow.org/tutorials/quickstart/beginner)\n",
    "9) [Recurrent Neural Network](https://www.tensorflow.org/guide/keras/working_with_rnns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f903576b",
   "metadata": {},
   "source": [
    "There is alot of algorithm I have mentioned. You don NOT have to test all of this (this would take you multiple weeks to get it done). What is really important here is the hands-on experience and practicing reading the documentation. There are lots and lots of resources online on what these algorithms are. I would watch statquest's youtube video on what these algorithms are. There are a lot of theoretical concepts with these algorithm as well if you are interested.\n",
    "\n",
    "In general all the methods (aside from ANN and RNN) uses the fit() and predict() workflow. Play around with it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956570cb",
   "metadata": {},
   "source": [
    "# Cross validation\n",
    "- In machine learning, we usually implement cross-validation to make sure our method is working properly. \n",
    "- For example, in a 5 fold cross validation, you divide the data into 5 parts, and use 4 of them to train the model, and 1 to test the model. We use the data we tested to compute the accuracy of the model.\n",
    "- We can do this using scikit-learn's [Kfold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)\n",
    "- See the code below for an example. I use support vector machine as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abc19f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 Accuracy: 0.15\n",
      "Fold 1 Accuracy: 0.3\n",
      "Fold 2 Accuracy: 0.1\n",
      "Fold 3 Accuracy: 0.1\n",
      "Fold 4 Accuracy: 0.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = np.random.rand(100,3)   #just some random matrix\n",
    "y = np.random.choice(5, size = 100)  # some random class\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle = True, random_state = 1)  #change this value if you are doing more than 5. For this week, just do 5\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    X_train = X[train_index, :]; y_train = y[train_index]\n",
    "    X_test = X[test_index, :]; y_test = y[test_index]\n",
    "    \n",
    "    mySVC = SVC(kernel = 'rbf', degree = 5 ,random_state = 1)  # you should fix random_state = 1, and just change the kfold shuffling\n",
    "    mySVC.fit(X_train, y_train)\n",
    "    y_pred = mySVC.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    print('Fold', i, 'Accuracy:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1264f7",
   "metadata": {},
   "source": [
    "- Notice that for kfold, I use the 'shuffle = Ture' and 'random_state = 1'. I fix the random state so that the data shuffling and the splitting is always the same. You should test different random_state values to see if your model achieves similar result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eba684",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "Scanpy is built on [AnnData](https://anndata.readthedocs.io/en/latest/). I will show how to construct the AnnData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb2b7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "935626b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'GSE75748cell'\n",
    "record_csv = pd.read_csv('./SingleCellDataProcess/data/' + data + '/' +  data + '_data.csv')\n",
    "labels_csv = pd.read_csv('./SingleCellDataProcess/data/' + data + '/' + data + '_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3851956f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 genes ['MKL2', 'CD109', 'ABTB1', 'MAST2', 'KAT5', 'WWC2', 'CD163', 'MYL2', 'UBE2Z', 'RGPD4']\n",
      "Data size: (19097, 1018)\n"
     ]
    }
   ],
   "source": [
    "gene_list = list(record_csv['Unnamed: 0'])\n",
    "sample_name = list(record_csv.keys())[1:]\n",
    "counts = record_csv.values[:, 1:].astype(float)\n",
    "print('First 10 genes', gene_list[:10])\n",
    "print('Data size:', counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f6104cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.AnnData(counts.T)\n",
    "adata.obs_names = sample_name\n",
    "adata.var_names = gene_list\n",
    "counts = None; sample_name = None; gene_list = None;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e35227",
   "metadata": {},
   "source": [
    "You can now use scanpy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb544d5d",
   "metadata": {},
   "source": [
    "##  Merging GSE84133 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a62485b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vec = ['GSE84133human1', 'GSE84133human2', 'GSE84133human3', 'GSE84133human4']\n",
    "sample_name_list = []\n",
    "counts_vec = []\n",
    "for data in data_vec:\n",
    "    record_csv = pd.read_csv('./SingleCellDataProcess/data/' + data + '/' +  data + '_data.csv')\n",
    "    labels_csv = pd.read_csv('./SingleCellDataProcess/data/' + data + '/' + data + '_labels.csv')\n",
    "    gene_list = list(record_csv['Unnamed: 0'])\n",
    "    sample_name = list(record_csv.keys())[1:]\n",
    "    sample_name_list += sample_name\n",
    "    counts = record_csv.values[:, 1:].astype(float)\n",
    "    counts_vec.append(counts)\n",
    "counts_vec = np.concatenate(counts_vec, axis = 1)\n",
    "adata = ad.AnnData(counts_vec.T)\n",
    "adata.obs_names = sample_name_list\n",
    "adata.var_names = gene_list\n",
    "counts_vec = None; sample_name_list = None; gene_list = None;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfed26f",
   "metadata": {},
   "source": [
    "# Extra credit (just for discussion)\n",
    "- When we compute the accuracy, it is extremely important to think about what the result means?\n",
    "- For example, which cell types is misclassified the most? These can be used to further fine tune the model, or show something interesting about the data\n",
    "- For GSE84133 large data, you should test your model with one of the data, such as GSE84133human3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa6f3f7",
   "metadata": {},
   "source": [
    "# Some benchmark\n",
    "- GSE75748cell: about 0.8 accuracy\n",
    "- GSE75748time: 0.74-0.77\n",
    "- GSE84133: this really depends on what method you use. It can be VERY good with deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43407ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
